
Mathematical Formulations of Algorithms
This repository contains Jupyter Notebook files that explain the mathematical formulations and implementation of various algorithms from scratch. The notebooks provide step-by-step explanations and code examples for algorithms such as Linear Regression, Multiple Linear Regression, Gradient Descent, and more.

- [Table of Contents](#table-of-contents)
  * [Introduction](#introduction)
  * [Algorithms](#algorithms)
  * [Dependencies](#dependencies)
  * [Installation](#installation)
  * [Usage](#usage)
  * [Contributing](#contributing)
  * [License](#license)
 
## Introduction
In this repository, you will find Jupyter Notebook files that cover the mathematical formulations and implementation details of various algorithms. Each notebook focuses on a specific algorithm and provides clear explanations along with code snippets to help you understand and implement the algorithms from scratch.

## Algorithms
The following algorithms are covered in this repository:

- Linear Regression: This notebook explains the mathematical formulation and implementation of simple linear regression, a popular algorithm used for predicting a continuous target variable based on one or more independent variables.

- Multiple Linear Regression: This notebook expands on the concepts of linear regression and discusses the mathematical formulation and implementation of multiple linear regression, which allows for predicting a continuous target variable using multiple independent variables.

- Gradient Descent: This notebook explores the concept of gradient descent, an optimization algorithm commonly used in machine learning. It covers the mathematical formulation and step-by-step implementation of gradient descent for finding the minimum of a function.

## Dependencies
The following dependencies are required to run the Jupyter Notebook files:

- Python 3.x
- NumPy
- Matplotlib
- Pandas (if applicable)
